{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0278dd2-3f93-4ef0-9b1f-dc6d0fd382ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import silhouette_score\n",
    "from kneed import KneeLocator\n",
    "from scipy import stats  # Import the stats module for statistical methods\n",
    "from scipy.stats import shapiro, levene, kruskal\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "print(\"Successful Import!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11376d00-3551-46e4-a721-07b5b9971d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'file_path' with the path to your data file\n",
    "file_path = r\"C:\\Users\\Farhan\\Videos\\3D Mitochondrial Analysis\\Test Data.xlsx\"\n",
    "df = pd.read_excel(file_path) # Note: change pd.read_excel to pd.read_csv if you want to use a CSV file\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First few rows of the data:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48861581-0e5b-415e-9ffa-abda417a1c00",
   "metadata": {},
   "source": [
    "# Group by 'Image Name' and 'Cell Type', and calculate the number of unique 'Image Name' values in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ea2081-748d-495e-84b2-fc2e453c4010",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_image_counts = df.groupby(['Image Name', 'Cell Type']).nunique()\n",
    "\n",
    "print(\"\\nNote: Ensure that the image names are not repeating\")\n",
    "# Display the grouped DataFrame\n",
    "print(\"Unique image counts per cell type:\")\n",
    "display(unique_image_counts)\n",
    "\n",
    "# Group by 'Image Name' and 'Cell Type', and calculate the descriptive statistics for each group\n",
    "grouped = df.groupby(['Image Name', 'Cell Type']).describe()\n",
    "\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "# Display the grouped DataFrame\n",
    "display(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db83831e-2bcb-4c47-843a-7d438fc44990",
   "metadata": {},
   "source": [
    "# Display Box Plots of Grouped Data (Change Numeric Column Names Based on Your Own DataSet)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf0623-1cfc-4376-828a-a775d9088688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numeric columns.\n",
    "numeric_columns = ['Count', 'Total Volume', 'Mean Volume', 'Total Surface Area', 'Mean Surface Area', 'Sphericity (Weighted)', 'Branches', 'Branches/volume', 'Total Branch Length', 'Total Branch Length/volume', 'Mean Branch Length', 'Branch Junctions', 'Branch Junctions/volume', 'Branch End Points', 'Branch End Points/volume', 'Mean Branch Diameter']\n",
    "\n",
    "# Create a figure and axes objects\n",
    "fig, axes = plt.subplots(len(numeric_columns), 1, figsize=(10, len(numeric_columns) * 5))\n",
    "\n",
    "# For each numeric column\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    # Create a box plot for the overall data\n",
    "    axes[i].boxplot(df[col].dropna(), positions=[1], widths=0.5)\n",
    "\n",
    "    # For each cell type\n",
    "    for j, cell_type in enumerate(df['Cell Type'].unique(), start=2):\n",
    "        # Create a box plot for the cell type specific data\n",
    "        axes[i].boxplot(df[df['Cell Type'] == cell_type][col].dropna(), positions=[j], widths=0.2)\n",
    "\n",
    "    # Set the x-ticks and x-tick labels\n",
    "    axes[i].set_xticks(range(1, len(df['Cell Type'].unique()) + 2))\n",
    "    axes[i].set_xticklabels(['Overall'] + list(df['Cell Type'].unique()))\n",
    "\n",
    "    # Set the title\n",
    "    axes[i].set_title(f'Box plot of {col}')\n",
    "\n",
    "    # Set the y-label\n",
    "    axes[i].set_ylabel(col)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081324ef-b354-4ae2-b140-4779331b257e",
   "metadata": {},
   "source": [
    "# Perform Correlation Analysis, Print Correlation Matrices, and Plot the Correlation Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42abb09b-f632-4ee1-a81c-30f753119f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations(df, method='spearman'): # Change the type of correlation you want to do in this line!\n",
    "    # Choose the correlation method\n",
    "    if method == 'pearson':\n",
    "        corr_func = stats.pearsonr\n",
    "    elif method == 'spearman':\n",
    "        corr_func = stats.spearmanr\n",
    "    else:\n",
    "        raise ValueError(\"method must be either 'pearson' or 'spearman'\")\n",
    "\n",
    "    # Get the list of numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "\n",
    "    # Initialize a DataFrame to hold the correlation coefficients and p-values\n",
    "    corr_df = pd.DataFrame(index=numeric_cols, columns=numeric_cols)\n",
    "    pval_df = pd.DataFrame(index=numeric_cols, columns=numeric_cols)\n",
    "\n",
    "    # Compute the correlation for each pair of columns\n",
    "    for i, col1 in enumerate(numeric_cols):\n",
    "        for j, col2 in enumerate(numeric_cols[i:]):\n",
    "           # Calculate correlation using the specified method, handling NaNs by dropping them\n",
    "            corr, pval = corr_func(df[col1].dropna(), df[col2].dropna())\n",
    "            corr_df.loc[col1, col2] = corr\n",
    "            pval_df.loc[col1, col2] = pval\n",
    "\n",
    "    # Apply Bonferroni correction to the p-values\n",
    "    num_comparisons = len(numeric_cols) * (len(numeric_cols) - 1) // 2 # Calculate number of pairs\n",
    "    pval_df = pval_df * num_comparisons\n",
    "\n",
    "    return corr_df, pval_df\n",
    "\n",
    "# Compute the correlations\n",
    "corr_df, pval_df = compute_correlations(df, method='spearman')  # or method='spearman'\n",
    "\n",
    "# Create a copy of the correlation matrix\n",
    "marked_corr_df = corr_df.copy()\n",
    "\n",
    "# Mark the correlation coefficients with significant p-values\n",
    "marked_corr_df[pval_df < 0.05] = marked_corr_df[pval_df < 0.05].astype(str) + '**'\n",
    "\n",
    "# Display the correlation coefficients as a table\n",
    "print(\"\\nTable 1: Correlation Coefficients\")\n",
    "display(marked_corr_df)\n",
    "print(\"** = P-value < 0.05\")\n",
    "\n",
    "print(\"--------------------------------------------\")\n",
    "\n",
    "# Display the p-values as a table\n",
    "#print(\"Table 2: P-values for Correlation Coefficients\")\n",
    "print(\"\\nP-values for Correlation Coefficients:\")\n",
    "display(pval_df)\n",
    "\n",
    "#print(\"\\nNote: The 'NaN' values in the table could be due to zeros or missing data in the corresponding columns.\")\n",
    "\n",
    "# Compute the correlations\n",
    "corr_df, pval_df = compute_correlations(df, method='spearman')  # or method='spearman'\n",
    "\n",
    "# Replace NaN values with 0\n",
    "corr_df.fillna(0, inplace=True)\n",
    "corr_df = corr_df.infer_objects(copy=False)\n",
    "# Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(corr_df, annot=False, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "#plt.savefig(r\"C:\\3D Mitochondrial Analysis\\PerCell_Original_data_heatmap_10-16-24.png\", bbox_inches='tight', dpi=800)\n",
    "plt.show()\n",
    "\n",
    "# Compute the correlations\n",
    "corr_df, pval_df = compute_correlations(df, method='spearman')  # or method='spearman'\n",
    "\n",
    "# Replace NaN values with 0\n",
    "corr_df.fillna(0, inplace=True)\n",
    "corr_df = corr_df.infer_objects(copy=False)\n",
    "# Create a heatmap of the correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(5, 5))  # Adjust as necessary\n",
    "sns.heatmap(corr_df, annot=False, cmap='coolwarm', ax=ax) # 'coolwarm' also works great\n",
    "plt.title('Correlation Heatmap (Per Cell) Control and FA Conditions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0de1b-39b2-438a-afae-b240aca59dad",
   "metadata": {},
   "source": [
    "# Perform PCA Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b465fd-cb8c-463c-a757-7afe410dbba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude non-numeric columns from df\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Initialize PCA with 2 components\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit and transform df_numeric, not df\n",
    "reduced_df = pca.fit_transform(df_numeric)\n",
    "\n",
    "# Plot the reduced data\n",
    "plt.scatter(reduced_df[:, 0], reduced_df[:, 1])\n",
    "plt.xlabel('Principal Component 1', fontsize=12)\n",
    "plt.ylabel('Principal Component 2', fontsize=12)\n",
    "plt.title('PCA Scatter Plot (Per Cell)', fontsize=16)\n",
    "#plt.savefig(r\"C:\\Videos\\3D Mitochondrial Analysis\\PerCell_PCA_Scatter_Plot_10-16-24.png\", bbox_inches='tight', dpi=800)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afe7979-8f7c-4178-a15f-f28474c3492d",
   "metadata": {},
   "source": [
    "# Identify optimal Cluster Count for your Own Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff0dfd6-feba-427b-8fac-8402b1d27059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude non-numeric columns from df\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "\n",
    "distortions = []\n",
    "K = range(1, 10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k, n_init=10, random_state=42).fit(df_numeric)  # Added n_init and random_state\n",
    "    distortions.append(sum(np.min(cdist(df_numeric, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / df_numeric.shape[0])\n",
    "\n",
    "# Use KneeLocator to find the elbow point\n",
    "kl = KneeLocator(range(1, 10), distortions, curve=\"convex\", direction=\"decreasing\")\n",
    "\n",
    "# Plot the elbow\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal \"k\" for clustering', fontsize=16)\n",
    "\n",
    "# Annotate the optimal k\n",
    "plt.annotate('Elbow point', xy=(kl.elbow, distortions[kl.elbow - 1]),\n",
    "             xytext=(kl.elbow, distortions[kl.elbow - 1] + 0.05),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "# Add a red dot to mark the elbow point\n",
    "plt.plot(kl.elbow, distortions[kl.elbow - 1], 'ro')\n",
    "\n",
    "# Save and show the plot\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal \"k\" for clustering', fontsize=16)\n",
    "#plt.savefig(r\"C:\\Videos\\3D Mitochondrial Analysis\\PerCell_Elbow_K_Plot_10-16-24.png\", bbox_inches='tight', dpi=800)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d0432-e8fd-4a6a-8d23-e32fb0d40f83",
   "metadata": {},
   "source": [
    "# Use the Optimal Cluster Count from the Elbow Method below (Change the `n_clusters` to whatever you get from the elbow method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ede6f6-aa00-4e6c-a70d-d9303f48782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, n_init=10, random_state=42)  # Choose the appropriate number of clusters, added random_state\n",
    "kmeans.fit(reduced_df)\n",
    "\n",
    "# The cluster labels are in kmeans.labels_\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "# You can now examine the features of the mitochondria in each cluster\n",
    "for cluster in set(kmeans.labels_):\n",
    "    print(f\"\\n Features of Mitochondria in Cluster {cluster}:\")\n",
    "    display(df[df['cluster'] == cluster].describe())\n",
    "\n",
    "\n",
    "# 'labels' is an array of cluster labels for each data point\n",
    "# 'df' is original dataset\n",
    "score = silhouette_score(reduced_df, kmeans.labels_)\n",
    "\n",
    "# Create a scatter plot of the reduced data\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(reduced_df[:, 0], reduced_df[:, 1], c=kmeans.labels_, cmap='viridis')\n",
    "\n",
    "# If your clustering algorithm provides cluster centers (like KMeans), you can plot them as well\n",
    "plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300, c='red')\n",
    "\n",
    "plt.xlabel('Principal Component 1', fontsize=12)\n",
    "plt.ylabel('Principal Component 2', fontsize=12)\n",
    "plt.title('PCA Scatter Plot with K-Mean Clusters', fontsize=16)\n",
    "#plt.savefig(r\"C:\\Users\\Farhan\\Videos\\3D Mitochondrial Analysis\\PerCell_K-Mean_Clusters_Plot_10-16-24.png\", bbox_inches='tight', dpi=800) # Save K-mean clustering PNG to your folder\n",
    "plt.show()\n",
    "\n",
    "#print(\"Silhouette Score: \", score)\n",
    "print(\"\\nNote: The Silhouette Score is a single measure that provides a summary of the compactness and separation of the clusters in your data. It’s calculated using all the data points and their corresponding cluster assignments. The Silhouette Score is a measure of how similar an object is to its own cluster compared to other clusters. It ranges from -1 to 1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.\")\n",
    "\n",
    "# Save the entire dataframe with cluster labels to a CSV file\n",
    "#df.to_csv(r\"D:\\Mitochondria Morphology Analysis\\clustered_PerCell_data_07-17-24.csv\", index=False)\n",
    "\n",
    "# Assume that 'df' is your DataFrame and 'cluster' is the column with cluster labels\n",
    "for col in df_numeric.columns:\n",
    "    if col != 'cluster':\n",
    "        sns.boxplot(x='cluster', y=col, data=df)\n",
    "        plt.title(f'Box plot of {col} by cluster')\n",
    "\n",
    "        # Save the plot as a PNG file\n",
    "        #plt.savefig(f\"D:\\\\Mitochondria Morphology Analysis\\\\PerCell_ClusteredBoxPlots__07-17-24_{col}.png\") # use \"\\\\\" Double slashes for paths in this line\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8c7b5-14fb-4cec-b40e-a2260915f04b",
   "metadata": {},
   "source": [
    "# Group Data based on Clustering and Display Graphs for each paramter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd95bd48-fdfb-4c65-9e54-ca6aed799d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude non-numeric columns from df\n",
    "df_numeric = df.select_dtypes(include=[np.number])\n",
    "\n",
    "# Calculate the mean values\n",
    "mean_values = df_numeric.groupby('cluster').mean()\n",
    "#mean_values.to_csv(r\"D:\\Mitochondria Morphology Analysis\\PerCell_MeanMitoValuesByCluster_data_07-17-24.csv\", index=False)\n",
    "\n",
    "# Create a heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 8))  # Adjust as necessary\n",
    "sns.heatmap(mean_values, cmap='coolwarm', annot=False)\n",
    "plt.title('Heatmap of mean mitochondrial parameter values by cluster')\n",
    "#plt.savefig(r\"D:\\Mitochondria Morphology Analysis\\PerCell_MeanMitoValuesByCluster_07-17-24.png\", bbox_inches='tight',dpi=2400)\n",
    "plt.show()\n",
    "print(\"\\nMean Values by Cluster:\")\n",
    "display(mean_values)\n",
    "# Group by 'Cell Type' and 'cluster', and calculate the number of distinct images in each group\n",
    "grouped = df.groupby(['Cell Type', 'cluster'])['Image Name'].nunique()\n",
    "\n",
    "# Calculate the total number of distinct images in each cell type\n",
    "total = df.groupby('Cell Type')['Image Name'].nunique()\n",
    "\n",
    "# Divide the grouped data by the total data and multiply by 100 to get percentages\n",
    "percentages = grouped / total * 100\n",
    "\n",
    "print(\"\\nTable _Percent of Cells in each Cluster:\")\n",
    "display(percentages)\n",
    "print(\"-------------------------------------------------------------\")\n",
    "#print(\"Table _Total Number of Cells from each Cell Type in each Cluster:\")\n",
    "print(\"\\nTotal Number of Cells from each Cell Type in each Cluster:\")\n",
    "display(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04967825-de4f-4dbc-91f9-407bcad33838",
   "metadata": {},
   "source": [
    "# Find the Most Common Cluster For Each Image/Cell (Assuming that each Image is One Cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c22b96-11ce-4a83-aa00-bbafa3fa98e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most common cluster for each image (or Cell, if you have cropped your images to represent one cell per Image)\n",
    "image_clusters = df.groupby('Image Name')['cluster'].agg(lambda x: x.value_counts().index[0])\n",
    "\n",
    "# Add the cell type information\n",
    "image_clusters = df.drop_duplicates('Image Name').set_index('Image Name')['Cell Type'].map(str) + ' ' + image_clusters.map(str)\n",
    "\n",
    "# Count the number of images of each cell type in each cluster\n",
    "image_cluster_counts = image_clusters.value_counts()\n",
    "\n",
    "# Convert the image_cluster_counts Series to a DataFrame and reset the index\n",
    "image_cluster_counts_df = image_cluster_counts.reset_index()\n",
    "image_cluster_counts_df.columns = ['Cell Type and Cluster', 'Count']\n",
    "\n",
    "# Convert the 'Cell Type and Cluster' column to two separate columns\n",
    "image_cluster_counts_df[['Cell Type', 'Cluster']] = image_cluster_counts_df['Cell Type and Cluster'].str.split(' ', expand=True)\n",
    "\n",
    "# Pivot the DataFrame to get the counts for each cluster in separate columns\n",
    "pivot_df = image_cluster_counts_df.pivot(index='Cell Type', columns='Cluster', values='Count').fillna(0)\n",
    "\n",
    "# Create a stacked bar plot\n",
    "#pivot_df.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "#plt.title('Count of Each Cell Type in Each Cluster', fontsize=16)\n",
    "#plt.xlabel('Cell Type', fontsize=12)\n",
    "#plt.ylabel('Count', fontsize=12)\n",
    "#plt.xticks(rotation=0)  # Rotate the x-axis labels for better readability\n",
    "# plt.show()\n",
    "\n",
    "plt.figure()\n",
    "# Create a stacked bar plot\n",
    "ax = pivot_df.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "# Add the cell counts as text\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.text(x + width / 2,\n",
    "            y + height / 2,\n",
    "            '{:.0f}'.format(height),\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center')\n",
    "\n",
    "plt.title('Count of Each Cell Type in Each Cluster', fontsize=16)\n",
    "plt.xlabel('Cell Type', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=0)  # Rotate the x-axis labels for better readability\n",
    "#plt.savefig(r\"D:\\Mitochondria Morphology Analysis\\PerCell_CellTypePerCluster_07-17-24.png\", bbox_inches='tight', dpi=2400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851b7cd-7115-45e5-a771-b0ee3ae228e6",
   "metadata": {},
   "source": [
    "# Find the most common cluster for each image/cell under each exposure condition (Assuming that each Image is One Cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7380c8f2-84db-42af-9107-80470dfb1cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure_clusters = df.groupby(['Exposure Condition', 'Image Name'])['cluster'].agg(lambda x: x.value_counts().index[0])\n",
    "\n",
    "# Add the exposure condition information\n",
    "exposure_clusters = df.drop_duplicates('Image Name').set_index('Image Name')['Exposure Condition'].map(str) + '_' + exposure_clusters.map(str)\n",
    "\n",
    "# Count the number of images of each exposure condition in each cluster\n",
    "exposure_cluster_counts = exposure_clusters.value_counts()\n",
    "\n",
    "# Convert the exposure_cluster_counts Series to a DataFrame and reset the index\n",
    "exposure_cluster_counts_df = exposure_cluster_counts.reset_index()\n",
    "exposure_cluster_counts_df.columns = ['Exposure Condition and Cluster', 'Count']\n",
    "\n",
    "# Convert the 'Exposure Condition and Cluster' column to two separate columns\n",
    "exposure_cluster_counts_df[['Exposure Condition', 'Cluster']] = exposure_cluster_counts_df['Exposure Condition and Cluster'].str.split('_', expand=True)\n",
    "\n",
    "# Pivot the DataFrame to get the counts for each cluster in separate columns\n",
    "pivot_df = exposure_cluster_counts_df.pivot(index='Exposure Condition', columns='Cluster', values='Count').fillna(0)\n",
    "\n",
    "# Create a stacked bar plot\n",
    "plt.figure()\n",
    "ax = pivot_df.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "\n",
    "# Add the image counts as text\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy()\n",
    "    ax.text(x + width / 2,\n",
    "            y + height / 2,\n",
    "            '{:.0f}'.format(height),\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center')\n",
    "\n",
    "plt.title('Count of Each Exposure Condition in Each Cluster', fontsize=16)\n",
    "plt.xlabel('Exposure Condition', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=90)  # Rotate the x-axis labels for better readability\n",
    "#plt.savefig(r\"D:\\Mitochondria Morphology Analysis\\PerCell_CellsPerClusterPerExposure_07-17-24.png\", bbox_inches='tight', dpi=2400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aceaeec-e8f9-4948-b13c-3449c0d1f17f",
   "metadata": {},
   "source": [
    "# Shapiro-Wilk test for normality & Levene's Test for Equality of Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7ef4c0-ff3a-490b-8566-9df276077c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# For each numeric column\n",
    "for col in numeric_columns:\n",
    "    # Perform the Shapiro-Wilk test for normality\n",
    "    sw_stat, sw_p_val = shapiro(df[col].dropna())\n",
    "    sw_test = 'Non-Normal' if sw_p_val < 0.05 else 'Normal'\n",
    "\n",
    "    # For Levene's test, we need at least two groups. Let's use 'Exposure Condition' for grouping\n",
    "    groups = [group[col].dropna() for name, group in df.groupby('Exposure Condition')]\n",
    "\n",
    "    # Perform Levene's test for equality of variances\n",
    "    lev_stat, lev_p_val = levene(*groups)\n",
    "    lev_test = 'Unequal Variances' if lev_p_val < 0.05 else 'Equal Variances'\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append(pd.DataFrame({'Mitochondrial Parameter': [col], 'Shapiro-Wilk Statistic': [sw_stat], 'Shapiro-Wilk P-value': [sw_p_val], 'Shapiro-Wilk Test': [sw_test], 'Levene Statistic': [lev_stat], 'Levene P-value': [lev_p_val], 'Levene Test': [lev_test]}))\n",
    "\n",
    "# Concatenate the results into a single DataFrame\n",
    "results_SWL_df = pd.concat(results, ignore_index=True)\n",
    "#results_SWL_df.to_csv(r\"D:\\Julia-Fura_FF_Data_Analysis\\Mitochondria Morphology Analysis\\clustered_PerCell_Shapiro-wilk_Levene's Test_07-16-24.csv\", index=False)\n",
    "# Display the results\n",
    "print(\"\\nShapiro-Wilk and Levene's Test Results:\")\n",
    "display(results_SWL_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1be785-c4b2-44e6-a4a9-1f7d6a90cda2",
   "metadata": {},
   "source": [
    "# Kuskal-Wallis Test (non-parametric one-way ANOVA that tests whether samples originat from the same distribution. It is used for comparing two or more independent samples of **equal or different sample sizes.**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234863b0-eb69-4033-953a-f496e8892893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# For each numeric column\n",
    "for col in numeric_columns:\n",
    "    # Split the data into groups based on 'Exposure Condition'\n",
    "    groups = [group[col].dropna() for name, group in df.groupby('Exposure Condition')]\n",
    "\n",
    "    # Perform the Kruskal-Wallis H-test\n",
    "    h_stat, p_val = kruskal(*groups)\n",
    "\n",
    "    # Interpret the result\n",
    "    kw_test = 'Significant' if p_val < 0.05 else 'Not Significant'\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append(pd.DataFrame({'Mitochondrial Parameter': [col], 'Kruskal-Wallis H-statistic': [h_stat], 'Kruskal-Wallis P-value': [p_val], 'Kruskal-Wallis Test': [kw_test]}))\n",
    "\n",
    "# Concatenate the results into a single DataFrame\n",
    "results_KW_df = pd.concat(results, ignore_index=True)\n",
    "#results_KW_df.to_csv(r\"D:\\Julia-Fura_FF_Data_Analysis\\Mitochondria Morphology Analysis\\clustered_PerCell_Kruskal-Wallis_Test_Mitochondrial_Parameter_Across_FA_07-16-24.csv\", index=False)\n",
    "# Print the title\n",
    "print(\"\\nTable 1: Kruskal-Wallis H-Test Results for Each Mitochondrial Parameter Across Exposure Conditions\")\n",
    "\n",
    "# Display the results\n",
    "display(results_KW_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8604fc-1356-48dd-bc59-61f59decda18",
   "metadata": {},
   "source": [
    "# Dunn's Post-Hoc Pair-wise comparision (Uses Bonferroni Correction for multiple comparision. Adjust to holm if less conservative correction is needed; adjust to Benjamini-Hochberg (BH) or False Discovery Rate (FDR) if more liberal correction of p-values is required). \n",
    "\n",
    "### **Holm Correction:** The Holm correction is less conservative than Bonferroni. It adjusts p-values by comparing them to decreasing thresholds based on the rank of their significance.\n",
    "### **Benjamini-Hochberg (BH) or False Discovery Rate (FDR):** The Benjamini-Hochberg (BH) procedure controls the False Discovery Rate (FDR), which is the expected proportion of rejected null hypotheses that are actually true. It's more liberal (less conservative) than Bonferroni and Holm, making it a good choice when you have a large number of tests and are more interested in controlling the proportion of false positives rather than the overall probability of at least one false positive.\n",
    "### **Benjamini-Yekutieli (BY):** The Benjamini-Yekutieli procedure is another FDR control method that accounts for dependence among the tests, making it more robust to deviations in the distribution of test statistics from independence.\n",
    "\n",
    "### **Additional Notes:**\n",
    "##### **Conservatism:** Bonferroni is the most conservative (least likely to find a significant result), followed by Holm, and then BH/FDR/BY. Which one is most appropriate depends on the context of your research and how you want to balance the risk of false positives and false negatives.\n",
    "\n",
    "##### **Number of Tests:** When you have a large number of comparisons, Bonferroni can be overly strict, and you might want to consider a more liberal method like FDR or BY.\n",
    "\n",
    "##### **Assumptions:** BH/FDR assumes the tests are independent or weakly dependent (although BY can account for dependency). If your tests are strongly dependent, you might need to consider other more specialized methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b8f9d-857d-489f-91d2-2bff09cdd121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store all results\n",
    "all_results = []\n",
    "\n",
    "# For each numeric column\n",
    "for col in numeric_columns:\n",
    "    # Perform Dunn's test\n",
    "    results_dunn = sp.posthoc_dunn(df, val_col=col, group_col='Exposure Condition', p_adjust='bonferroni') #(Change 'bonferroni' to 'holm', 'fdr_bh', or 'fdr_by' based on your p-value correction needs)\n",
    "\n",
    "    # Add a column for the mitochondrial parameter\n",
    "    results_dunn['Mitochondrial Parameter'] = col\n",
    "\n",
    "    # Append the results to all_results list\n",
    "    all_results.append(results_dunn)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"\\nDunn's post-hoc test for {col}:\")\n",
    "    display(results_dunn)\n",
    "\n",
    "# Concatenate all results into a single DataFrame\n",
    "results_df = pd.concat(all_results)\n",
    "\n",
    "# Save all results to a CSV file\n",
    "#results_df.to_csv(r\"D:\\Julia-Fura_FF_Data_Analysis\\Mitochondria Morphology Analysis\\clustered_PerCell_Dunn_Test_w_Bonferroni_FA_07-16-24.csv\", index=True)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize an empty DataFrame to store all results\n",
    "all_results = pd.DataFrame()\n",
    "\n",
    "# For each numeric column\n",
    "for col in numeric_columns:\n",
    "    # Perform Dunn's test\n",
    "    results_dunn = sp.posthoc_dunn(df, val_col=col, group_col='Exposure Condition', p_adjust='bonferroni')\n",
    "\n",
    "    # Add a level to the columns for the mitochondrial parameter\n",
    "    results_dunn.columns = pd.MultiIndex.from_product([[col], results_dunn.columns])\n",
    "\n",
    "    # Concatenate the results into the all_results DataFrame\n",
    "    all_results = pd.concat([all_results, results_dunn], axis=1)\n",
    "\n",
    "# Create a heatmap\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(all_results, cmap='coolwarm', annot=False, fmt=\".2f\")\n",
    "\n",
    "plt.title('Heatmap of Pairwise Dunn\\'s P-values for All Mitochondrial Parameters', fontsize=16, y=1.05)\n",
    "plt.xlabel('Exposure Condition and Mitochondrial Parameter', fontsize=12)\n",
    "plt.ylabel('Exposure Condition', fontsize=12)\n",
    "\n",
    "# Save the heatmap as a PNG file\n",
    "#plt.savefig(r\"D:\\Mitochondria Morphology Analysis\\clustered_PerCell_Dunn_Test_w_Bonferroni_FA_07-16-24.png\", bbox_inches='tight', dpi=2400)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
